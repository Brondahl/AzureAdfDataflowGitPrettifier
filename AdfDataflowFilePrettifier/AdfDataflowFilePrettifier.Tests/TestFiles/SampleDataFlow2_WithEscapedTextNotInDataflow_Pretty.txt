{
	"name": "GenericSCDType2_CopiedFromMicrosoftTemplateDataflows",
	"properties": {
		"folder": {
			"name": "GenericSCD"
		},
		"type": "MappingDataFlow",
		"description": "We've identified 2 short-comings in ADF w.r.t. array parameters:\n#1 It's quite hard to define an empty array.\n#2 Passing array parameters into Dataflows is badly broken. (currently)\n\nWhen invoking this dataflow, if you want to pass an empty array leave the parameter blank and allow this default to do it.\nOtherwise, to pass an array with actual values, provide a *string* holding a valid expression in the *DATAFLOW* syntax,\nwhich resolves to the relevant array.\n\n(For reference:\nIn the pipeline syntax, you can use `@take(array(999),0)` to define an empty array. But see above, for passing params, just leave it blank here.\nIn the dataflow syntax, you can use `filter([1], #item != 1)`.)\n\n\nTo provide a hard-coded array of values, it's easiest to pass:\n    array(val1, val2)\n\nTo provide a dynamic array, you'll need to dynamically construct the equivalent of the above. For example:\n    array(@\\{join(variables('myVariable'), ',')\\})\n\nThat's a *pipeline* expression which resolves to the string: `array(val1, val2, val3)`, based on the contents of the array\nvariable you *actually* want to be passing.\n**NOTE** there's no \"@\" symbol at the start of that string, neither in the Pipeline expression nor in the string value that it resolves to.\n\nAs mentioned at the start, this workaround appears to be necessary because of a direct bug in ADF, so in the future, such faffing may not be necessary.",
		"typeProperties": {
			"sources": [
				{
					"dataset": {
						"referenceName": "GenericDataset",
						"type": "DatasetReference"
					},
					"name": "GenericInput"
				},
				{
					"dataset": {
						"referenceName": "SqlDimension",
						"type": "DatasetReference"
					},
					"name": "ExistingDimensionTable"
				}
			],
			"sinks": [
				{
					"dataset": {
						"referenceName": "SqlDimension",
						"type": "DatasetReference"
					},
					"name": "DimensionTableSink"
				}
			],
			"transformations": [
				{
					"name": "NewAndUpdatedRows"
				},
				{
					"name": "AddHashInput"
				},
				{
					"name": "AddHashExisting"
				},
				{
					"name": "GetMaxSurrogateKey"
				},
				{
					"name": "AddKey"
				},
				{
					"name": "JoinWithMaxSurrogateKey"
				},
				{
					"name": "AddDimensionColumns"
				},
				{
					"name": "FilterForUpdatedValues"
				},
				{
					"name": "UpdateObsolete"
				},
				{
					"name": "DropUnwantedColsInput"
				},
				{
					"name": "UnionAllData"
				},
				{
					"name": "MarkAsUpdate"
				},
				{
					"name": "DropUnwantedColumns"
				},
				{
					"name": "MarkAsInsert"
				},
				{
					"name": "FilterForActive"
				}
			],
			"script": "
parameters{
	PrimaryKey as string ('ID'),
	Columns as string ('Player,Team,Salary')
}
source(allowSchemaDrift: true,
	validateSchema: false) ~> GenericInput
source(allowSchemaDrift: true,
	validateSchema: false,
	isolationLevel: 'READ_UNCOMMITTED',
	format: 'table') ~> ExistingDimensionTable
AddHashInput, AddHashExisting exists(AddHashInput@id_hash == AddHashExisting@id_hash
	&& AddHashInput@columns_hash == AddHashExisting@columns_hash,
	negate:true,
	broadcast: 'auto')~> NewAndUpdatedRows
GenericInput derive(id_hash = md5(byName($PrimaryKey)),
		columns_hash = md5(byNames(split($Columns,',')))) ~> AddHashInput
FilterForActive derive(id_hash = md5(byNames(split($PrimaryKey,','))),
		columns_hash = md5(byNames(split($Columns,',')))) ~> AddHashExisting
AddHashExisting aggregate(MaxSurrogateKey = max(toInteger(byName('Key')))) ~> GetMaxSurrogateKey
NewAndUpdatedRows keyGenerate(output(Key as long),
	startAt: 1L) ~> AddKey
AddKey, GetMaxSurrogateKey join(Key == MaxSurrogateKey || true(),
	joinType:'cross',
	broadcast: 'right')~> JoinWithMaxSurrogateKey
JoinWithMaxSurrogateKey derive(Key = Key + MaxSurrogateKey,
		Active = 1,
		ActiveStartTime = currentUTC(),
		ActiveEndTime = toTimestamp(toString(null()))) ~> AddDimensionColumns
AddHashExisting, NewAndUpdatedRows exists(AddHashExisting@id_hash == AddHashInput@id_hash,
	negate:false,
	broadcast: 'auto')~> FilterForUpdatedValues
FilterForUpdatedValues derive(Active = 0,
		ActiveEndTime = currentUTC()) ~> UpdateObsolete
AddDimensionColumns select(mapColumn(
		each(match(!in(['id_hash','columns_hash','MaxSurrogateKey'],name)))
	),
	skipDuplicateMapInputs: true,
	skipDuplicateMapOutputs: true) ~> DropUnwantedColsInput
MarkAsInsert, DropUnwantedColumns union(byName: true)~> UnionAllData
UpdateObsolete alterRow(updateIf(true())) ~> MarkAsUpdate
MarkAsUpdate select(mapColumn(
		each(match(!in(['id_hash','columns_hash','MaxSurrogateKey'],name)))
	),
	skipDuplicateMapInputs: true,
	skipDuplicateMapOutputs: true) ~> DropUnwantedColumns
DropUnwantedColsInput alterRow(insertIf(true())) ~> MarkAsInsert
ExistingDimensionTable filter(toInteger(byName('Active')) == 1) ~> FilterForActive
UnionAllData sink(allowSchemaDrift: true,
	validateSchema: false,
	deletable:false,
	insertable:true,
	updateable:true,
	upsertable:false,
	keys:[($PrimaryKey)],
	format: 'table',
	skipDuplicateMapInputs: true,
	skipDuplicateMapOutputs: true) ~> DimensionTableSink
"
		}
	}
}