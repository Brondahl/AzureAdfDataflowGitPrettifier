{
	"name": "GenericSCDType2_CopiedFromMicrosoftTemplateDataflows",
	"properties": {
		"folder": {
			"name": "GenericSCD"
		},
		"type": "MappingDataFlow",
		"description": "We've identified 2 short-comings in ADF w.r.t. array parameters:\n#1 It's quite hard to define an empty array.\n#2 Passing array parameters into Dataflows is badly broken. (currently)\n\nWhen invoking this dataflow, if you want to pass an empty array leave the parameter blank and allow this default to do it.\nOtherwise, to pass an array with actual values, provide a *string* holding a valid expression in the *DATAFLOW* syntax,\nwhich resolves to the relevant array.\n\n(For reference:\nIn the pipeline syntax, you can use `@take(array(999),0)` to define an empty array. But see above, for passing params, just leave it blank here.\nIn the dataflow syntax, you can use `filter([1], #item != 1)`.)\n\n\nTo provide a hard-coded array of values, it's easiest to pass:\n    array(val1, val2)\n\nTo provide a dynamic array, you'll need to dynamically construct the equivalent of the above. For example:\n    array(@\\{join(variables('myVariable'), ',')\\})\n\nThat's a *pipeline* expression which resolves to the string: `array(val1, val2, val3)`, based on the contents of the array\nvariable you *actually* want to be passing.\n**NOTE** there's no \"@\" symbol at the start of that string, neither in the Pipeline expression nor in the string value that it resolves to.\n\nAs mentioned at the start, this workaround appears to be necessary because of a direct bug in ADF, so in the future, such faffing may not be necessary.",
		"typeProperties": {
			"sources": [
				{
					"dataset": {
						"referenceName": "GenericDataset",
						"type": "DatasetReference"
					},
					"name": "GenericInput"
				},
				{
					"dataset": {
						"referenceName": "SqlDimension",
						"type": "DatasetReference"
					},
					"name": "ExistingDimensionTable"
				}
			],
			"sinks": [
				{
					"dataset": {
						"referenceName": "SqlDimension",
						"type": "DatasetReference"
					},
					"name": "DimensionTableSink"
				}
			],
			"transformations": [
				{
					"name": "NewAndUpdatedRows"
				},
				{
					"name": "AddHashInput"
				},
				{
					"name": "AddHashExisting"
				},
				{
					"name": "GetMaxSurrogateKey"
				},
				{
					"name": "AddKey"
				},
				{
					"name": "JoinWithMaxSurrogateKey"
				},
				{
					"name": "AddDimensionColumns"
				},
				{
					"name": "FilterForUpdatedValues"
				},
				{
					"name": "UpdateObsolete"
				},
				{
					"name": "DropUnwantedColsInput"
				},
				{
					"name": "UnionAllData"
				},
				{
					"name": "MarkAsUpdate"
				},
				{
					"name": "DropUnwantedColumns"
				},
				{
					"name": "MarkAsInsert"
				},
				{
					"name": "FilterForActive"
				}
			],
			"script": "parameters{\n\tPrimaryKey as string ('ID'),\n\tColumns as string ('Player,Team,Salary')\n}\nsource(allowSchemaDrift: true,\n\tvalidateSchema: false) ~> GenericInput\nsource(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tisolationLevel: 'READ_UNCOMMITTED',\n\tformat: 'table') ~> ExistingDimensionTable\nAddHashInput, AddHashExisting exists(AddHashInput@id_hash == AddHashExisting@id_hash\n\t&& AddHashInput@columns_hash == AddHashExisting@columns_hash,\n\tnegate:true,\n\tbroadcast: 'auto')~> NewAndUpdatedRows\nGenericInput derive(id_hash = md5(byName($PrimaryKey)),\n\t\tcolumns_hash = md5(byNames(split($Columns,',')))) ~> AddHashInput\nFilterForActive derive(id_hash = md5(byNames(split($PrimaryKey,','))),\n\t\tcolumns_hash = md5(byNames(split($Columns,',')))) ~> AddHashExisting\nAddHashExisting aggregate(MaxSurrogateKey = max(toInteger(byName('Key')))) ~> GetMaxSurrogateKey\nNewAndUpdatedRows keyGenerate(output(Key as long),\n\tstartAt: 1L) ~> AddKey\nAddKey, GetMaxSurrogateKey join(Key == MaxSurrogateKey || true(),\n\tjoinType:'cross',\n\tbroadcast: 'right')~> JoinWithMaxSurrogateKey\nJoinWithMaxSurrogateKey derive(Key = Key + MaxSurrogateKey,\n\t\tActive = 1,\n\t\tActiveStartTime = currentUTC(),\n\t\tActiveEndTime = toTimestamp(toString(null()))) ~> AddDimensionColumns\nAddHashExisting, NewAndUpdatedRows exists(AddHashExisting@id_hash == AddHashInput@id_hash,\n\tnegate:false,\n\tbroadcast: 'auto')~> FilterForUpdatedValues\nFilterForUpdatedValues derive(Active = 0,\n\t\tActiveEndTime = currentUTC()) ~> UpdateObsolete\nAddDimensionColumns select(mapColumn(\n\t\teach(match(!in(['id_hash','columns_hash','MaxSurrogateKey'],name)))\n\t),\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true) ~> DropUnwantedColsInput\nMarkAsInsert, DropUnwantedColumns union(byName: true)~> UnionAllData\nUpdateObsolete alterRow(updateIf(true())) ~> MarkAsUpdate\nMarkAsUpdate select(mapColumn(\n\t\teach(match(!in(['id_hash','columns_hash','MaxSurrogateKey'],name)))\n\t),\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true) ~> DropUnwantedColumns\nDropUnwantedColsInput alterRow(insertIf(true())) ~> MarkAsInsert\nExistingDimensionTable filter(toInteger(byName('Active')) == 1) ~> FilterForActive\nUnionAllData sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tdeletable:false,\n\tinsertable:true,\n\tupdateable:true,\n\tupsertable:false,\n\tkeys:[($PrimaryKey)],\n\tformat: 'table',\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true) ~> DimensionTableSink"
		}
	}
}